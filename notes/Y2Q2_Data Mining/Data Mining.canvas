{
	"nodes":[
		{"id":"c314eec5963e8013","type":"file","file":"attachments/Pasted image 20250120161007.png","x":-1180,"y":-6760,"width":160,"height":160},
		{"id":"5638eb86c506b802","type":"text","text":"Data dredging:\nYou will expect to find correlations (From any data set)\nyou will find what you want to find if you try hard enough\nthe data will confess to anything if tortured long enough\n\nAVOID USING CROSS VALIDATION (FIND OUT MEANINGLESSNESS)\n\nhow tf we gon do cross validation if we have no ground truth","x":-960,"y":-6580,"width":174,"height":160},
		{"id":"676912ea3dce1a91","type":"text","text":"Prosecutor's fallacy:\nP(A|B) != P(B|A)\n","x":-1400,"y":-6560,"width":174,"height":160},
		{"id":"0ae807517dc89449","type":"file","file":"notes/Y2Q2_Data Mining/Jaccard Similarity Distance.md","x":-940,"y":-6380,"width":174,"height":160},
		{"id":"1375529670ba679f","type":"text","text":"small /#dimensions -> use euclidean distance\n\nhuge amount of dimensions => use e.g. cosine","x":-1180,"y":-6340,"width":174,"height":160},
		{"id":"b3665979e1f47b3a","type":"link","url":"https://www.kaggle.com/","x":-1380,"y":-6340,"width":174,"height":160},
		{"id":"db293a934e8563cf","type":"link","url":"https://mattermost.tudelft.nl/select_team","x":-1420,"y":-6760,"width":174,"height":160},
		{"id":"5a7918f5086a14d7","type":"link","url":"https://peer.tudelft.nl/courses","x":-940,"y":-6780,"width":174,"height":160},
		{"id":"1b1f6396f89c969c","type":"text","text":"SPearman Correlation vs Pearson Correlation\n\nspearman's rho is used for measuring the monotonocity of two variables, while the pearsson correlation will mearsure only the linear correlations.\n\n","x":-1180,"y":-6980,"width":174,"height":160},
		{"id":"769da6e3f6455734","type":"file","file":"attachments/Pasted image 20241216224525.png","x":-940,"y":-6980,"width":174,"height":107},
		{"id":"60f05963dba5701b","type":"link","url":"https://www.kdnuggets.com/","x":-700,"y":-6860,"width":174,"height":160},
		{"id":"94d21923cd9f50c3","type":"text","text":"Redlining effect:\n\nremoving the sensitive feature does not remove the ability to discriminate => other attributes can be correlated and therefore infer them.","x":-700,"y":-6680,"width":174,"height":160},
		{"id":"61d149e11a923374","type":"file","file":"notes/Y2Q2_Data Mining/KL-divergence measure.md","x":-700,"y":-6460,"width":174,"height":160},
		{"id":"743d697f09d124fe","type":"text","text":"# Heterogeneous data types\n\nNumerical values\nCategorical data\ntext","x":-700,"y":-6260,"width":174,"height":160},
		{"id":"a6a9566eb9948406","type":"link","url":"https://queue.tudelft.nl/","x":-900,"y":-6140,"width":174,"height":160},
		{"id":"d64d0d7c8016e259","type":"file","file":"notes/Y2Q2_Data Mining/Distance Metric.md","x":-1134,"y":-6020,"width":174,"height":160},
		{"id":"3faa3b7cc7a42ce2","type":"text","text":"# Cross entropy\n\n![[Pasted image 20241118150757.png]]","x":-1374,"y":-6060,"width":174,"height":160},
		{"id":"5c383bdcb82e0faa","type":"file","file":"attachments/Pasted image 20241118144734.png","x":-1594,"y":-6180,"width":159,"height":160},
		{"id":"a8026b68cca84ea5","type":"file","file":"notes/Y2Q2_Data Mining/NOT ON EXAM.md","x":-1640,"y":-6460,"width":174,"height":160},
		{"id":"d6074c54ce077a12","type":"link","url":"https://weblab.tudelft.nl/","x":-1640,"y":-6920,"width":174,"height":160},
		{"id":"fb63a8b0cd20e223","type":"text","text":"Cross validation for recommender systems\nlarge data -> leave on out \nSpaprse data  -> k-fold with small k \n","x":-1400,"y":-7000,"width":174,"height":160},
		{"id":"dd3a93c066741929","type":"text","text":"Manifold learning\n- Manifolds\n  t-Disttributed Stochastic Neighbor Embedding (t-SNE)\n  - Uniform Manifold AApproximation and Projection (UMA)\n- DImensionality reduction: When is PCA not enough?","x":-1134,"y":-7180,"width":174,"height":160},
		{"id":"1d2915e7c0033a27","type":"file","file":"attachments/DM2024_lecture1_Introduction.pdf","x":-853,"y":-7200,"width":174,"height":160},
		{"id":"99b6dead42c7b6f0","type":"file","file":"notes/Y2Q2_Data Mining/Cosine similarity.md","x":-613,"y":-7120,"width":174,"height":160},
		{"id":"7f130966584c47f6","type":"file","file":"attachments/dm_book.pdf","x":-500,"y":-6900,"width":174,"height":160},
		{"id":"f366e44bfef7a462","type":"link","url":"https://brightspace.tudelft.nl/d2l/le/content/680741/Home","x":-500,"y":-6700,"width":174,"height":160},
		{"id":"cf2ea9039af26bb2","type":"file","file":"attachments/dm_book2.pdf","x":-460,"y":-6480,"width":174,"height":160},
		{"id":"f4d91e11f8f46756","type":"link","url":"https://answers.ewi.tudelft.nl/","x":-460,"y":-6260,"width":174,"height":160},
		{"id":"71978c8d20ceb704","type":"file","file":"notes/Y2Q2_Data Mining/Data Mining.md","x":-1180,"y":-6560,"width":174,"height":160},
		{"id":"5127864e4a7945e0","type":"link","url":"https://peer.tudelft.nl/courses","x":-1640,"y":-6700,"width":174,"height":160},
		{"id":"de1e65ac6c972ebc","type":"file","file":"attachments/Pasted image 20250120161129.png","x":-2080,"y":-6740,"width":399,"height":180},
		{"id":"4db3fb6011aace3c","type":"file","file":"attachments/Pasted image 20250120161237.png","x":-2080,"y":-6520,"width":399,"height":144},
		{"id":"cfe0fe62cd6849ab","type":"file","file":"attachments/Pasted image 20250120161305.png","x":-2080,"y":-6312,"width":398,"height":92},
		{"id":"ea03c54d00a9d7f7","type":"file","file":"attachments/Pasted image 20250120161312.png","x":-2080,"y":-6152,"width":399,"height":104},
		{"id":"f814da75bb682d07","x":-1403,"y":-7210,"width":197,"height":170,"type":"link","url":"https://giorgi.tech/blog/minhashing/"},
		{"id":"34a2e3a6fda2f2ab","x":-1682,"y":-7160,"width":216,"height":200,"type":"link","url":"https://giorgi.tech/blog/locality-sensitive-hashing/"}
	],
	"edges":[]
}